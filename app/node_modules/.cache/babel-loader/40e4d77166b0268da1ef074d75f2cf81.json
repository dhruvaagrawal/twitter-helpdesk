{"ast":null,"code":"'use strict';\n\nconst cacache = require('cacache');\n\nconst fetch = require('node-fetch-npm');\n\nconst pipe = require('mississippi').pipe;\n\nconst ssri = require('ssri');\n\nconst through = require('mississippi').through;\n\nconst to = require('mississippi').to;\n\nconst url = require('url');\n\nconst stream = require('stream');\n\nconst MAX_MEM_SIZE = 5 * 1024 * 1024; // 5MB\n\nfunction cacheKey(req) {\n  const parsed = url.parse(req.url);\n  return `make-fetch-happen:request-cache:${url.format({\n    protocol: parsed.protocol,\n    slashes: parsed.slashes,\n    host: parsed.host,\n    hostname: parsed.hostname,\n    pathname: parsed.pathname\n  })}`;\n} // This is a cacache-based implementation of the Cache standard,\n// using node-fetch.\n// docs: https://developer.mozilla.org/en-US/docs/Web/API/Cache\n//\n\n\nmodule.exports = class Cache {\n  constructor(path, opts) {\n    this._path = path;\n    this.Promise = opts && opts.Promise || Promise;\n  } // Returns a Promise that resolves to the response associated with the first\n  // matching request in the Cache object.\n\n\n  match(req, opts) {\n    opts = opts || {};\n    const key = cacheKey(req);\n    return cacache.get.info(this._path, key).then(info => {\n      return info && cacache.get.hasContent(this._path, info.integrity, opts).then(exists => exists && info);\n    }).then(info => {\n      if (info && info.metadata && matchDetails(req, {\n        url: info.metadata.url,\n        reqHeaders: new fetch.Headers(info.metadata.reqHeaders),\n        resHeaders: new fetch.Headers(info.metadata.resHeaders),\n        cacheIntegrity: info.integrity,\n        integrity: opts && opts.integrity\n      })) {\n        const resHeaders = new fetch.Headers(info.metadata.resHeaders);\n        addCacheHeaders(resHeaders, this._path, key, info.integrity, info.time);\n\n        if (req.method === 'HEAD') {\n          return new fetch.Response(null, {\n            url: req.url,\n            headers: resHeaders,\n            status: 200\n          });\n        }\n\n        let body;\n        const cachePath = this._path; // avoid opening cache file handles until a user actually tries to\n        // read from it.\n\n        if (opts.memoize !== false && info.size > MAX_MEM_SIZE) {\n          body = new stream.PassThrough();\n          const realRead = body._read;\n\n          body._read = function (size) {\n            body._read = realRead;\n            pipe(cacache.get.stream.byDigest(cachePath, info.integrity, {\n              memoize: opts.memoize\n            }), body, err => body.emit(err));\n            return realRead.call(this, size);\n          };\n        } else {\n          let readOnce = false; // cacache is much faster at bulk reads\n\n          body = new stream.Readable({\n            read() {\n              if (readOnce) return this.push(null);\n              readOnce = true;\n              cacache.get.byDigest(cachePath, info.integrity, {\n                memoize: opts.memoize\n              }).then(data => {\n                this.push(data);\n                this.push(null);\n              }, err => this.emit('error', err));\n            }\n\n          });\n        }\n\n        return this.Promise.resolve(new fetch.Response(body, {\n          url: req.url,\n          headers: resHeaders,\n          status: 200,\n          size: info.size\n        }));\n      }\n    });\n  } // Takes both a request and its response and adds it to the given cache.\n\n\n  put(req, response, opts) {\n    opts = opts || {};\n    const size = response.headers.get('content-length');\n    const fitInMemory = !!size && opts.memoize !== false && size < MAX_MEM_SIZE;\n    const ckey = cacheKey(req);\n    const cacheOpts = {\n      algorithms: opts.algorithms,\n      metadata: {\n        url: req.url,\n        reqHeaders: req.headers.raw(),\n        resHeaders: response.headers.raw()\n      },\n      size,\n      memoize: fitInMemory && opts.memoize\n    };\n\n    if (req.method === 'HEAD' || response.status === 304) {\n      // Update metadata without writing\n      return cacache.get.info(this._path, ckey).then(info => {\n        // Providing these will bypass content write\n        cacheOpts.integrity = info.integrity;\n        addCacheHeaders(response.headers, this._path, ckey, info.integrity, info.time);\n        return new this.Promise((resolve, reject) => {\n          pipe(cacache.get.stream.byDigest(this._path, info.integrity, cacheOpts), cacache.put.stream(this._path, cacheKey(req), cacheOpts), err => err ? reject(err) : resolve(response));\n        });\n      }).then(() => response);\n    }\n\n    let buf = [];\n    let bufSize = 0;\n    let cacheTargetStream = false;\n    const cachePath = this._path;\n    let cacheStream = to((chunk, enc, cb) => {\n      if (!cacheTargetStream) {\n        if (fitInMemory) {\n          cacheTargetStream = to({\n            highWaterMark: MAX_MEM_SIZE\n          }, (chunk, enc, cb) => {\n            buf.push(chunk);\n            bufSize += chunk.length;\n            cb();\n          }, done => {\n            cacache.put(cachePath, cacheKey(req), Buffer.concat(buf, bufSize), cacheOpts).then(() => done(), done);\n          });\n        } else {\n          cacheTargetStream = cacache.put.stream(cachePath, cacheKey(req), cacheOpts);\n        }\n      }\n\n      cacheTargetStream.write(chunk, enc, cb);\n    }, done => {\n      cacheTargetStream ? cacheTargetStream.end(done) : done();\n    });\n    const oldBody = response.body;\n    const newBody = through({\n      highWaterMark: MAX_MEM_SIZE\n    });\n    response.body = newBody;\n    oldBody.once('error', err => newBody.emit('error', err));\n    newBody.once('error', err => oldBody.emit('error', err));\n    cacheStream.once('error', err => newBody.emit('error', err));\n    pipe(oldBody, to((chunk, enc, cb) => {\n      cacheStream.write(chunk, enc, () => {\n        newBody.write(chunk, enc, cb);\n      });\n    }, done => {\n      cacheStream.end(() => {\n        newBody.end(() => {\n          done();\n        });\n      });\n    }), err => err && newBody.emit('error', err));\n    return response;\n  } // Finds the Cache entry whose key is the request, and if found, deletes the\n  // Cache entry and returns a Promise that resolves to true. If no Cache entry\n  // is found, it returns false.\n\n\n  'delete'(req, opts) {\n    opts = opts || {};\n\n    if (typeof opts.memoize === 'object') {\n      if (opts.memoize.reset) {\n        opts.memoize.reset();\n      } else if (opts.memoize.clear) {\n        opts.memoize.clear();\n      } else {\n        Object.keys(opts.memoize).forEach(k => {\n          opts.memoize[k] = null;\n        });\n      }\n    }\n\n    return cacache.rm.entry(this._path, cacheKey(req) // TODO - true/false\n    ).then(() => false);\n  }\n\n};\n\nfunction matchDetails(req, cached) {\n  const reqUrl = url.parse(req.url);\n  const cacheUrl = url.parse(cached.url);\n  const vary = cached.resHeaders.get('Vary'); // https://tools.ietf.org/html/rfc7234#section-4.1\n\n  if (vary) {\n    if (vary.match(/\\*/)) {\n      return false;\n    } else {\n      const fieldsMatch = vary.split(/\\s*,\\s*/).every(field => {\n        return cached.reqHeaders.get(field) === req.headers.get(field);\n      });\n\n      if (!fieldsMatch) {\n        return false;\n      }\n    }\n  }\n\n  if (cached.integrity) {\n    return ssri.parse(cached.integrity).match(cached.cacheIntegrity);\n  }\n\n  reqUrl.hash = null;\n  cacheUrl.hash = null;\n  return url.format(reqUrl) === url.format(cacheUrl);\n}\n\nfunction addCacheHeaders(resHeaders, path, key, hash, time) {\n  resHeaders.set('X-Local-Cache', encodeURIComponent(path));\n  resHeaders.set('X-Local-Cache-Key', encodeURIComponent(key));\n  resHeaders.set('X-Local-Cache-Hash', encodeURIComponent(hash));\n  resHeaders.set('X-Local-Cache-Time', new Date(time).toUTCString());\n}","map":null,"metadata":{},"sourceType":"script"}